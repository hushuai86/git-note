<attachment contenteditable="false" data-atts="%5B%5D" data-aid=".atts-7b863e19-f411-4543-9061-bbc93c88781a"></attachment><h1>Ocean - 项目结构篇Ocean - 项目结构篇</h1><p>一.项目结构</p><p>ocean</p><p>&nbsp;&nbsp;-&nbsp;api</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alert-service-api</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;auditlog-service-api</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;device-service-api</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;email-service-api</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;map-service-api</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;ui-service-api</p><p>&nbsp;&nbsp;-&nbsp;kafka-connect （Kafaka connector 是一种用于在Kafka和其他系统之间可扩展的、可靠的流式传输数据的工具,主要分两种：source connector将数据从其他系统传输到指定的Kafka Topic，sink connecor 将数据从Kafka Topic 传输到其他系统，以下几个都是sink Connect）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;kafka-connect-cassandra&nbsp;</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;kafka-connect-mysql</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;kafka-connect-redis</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;kafka-connect-utility&nbsp;<strong>（</strong>用于对异常的Connector task进行自动恢复，原理是通过Rset API 查找Failed的task 并进行resume操作）</p><p>&nbsp;&nbsp;-&nbsp;kafka-producer（提供了Swagger 页面用于调用一些Api,定时定量发送Message到kafka 的topic用于测试）</p><p>&nbsp;&nbsp;-&nbsp;ocean-common</p><p>&nbsp;&nbsp;-&nbsp;ocean-db-migration (使用Flyway 运行 db upgrade script)</p><p>&nbsp;&nbsp;-&nbsp;ocean-ui （Vue.js project）</p><p>&nbsp;&nbsp;-&nbsp;openmaptiles-server (搭建地图服务于k8s)</p><p>&nbsp;&nbsp;-&nbsp;percona （搭建percona数据库于k8s）</p><p>&nbsp;&nbsp;-&nbsp;service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;alert-service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;auditlog-service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;device-service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;email-service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;iot-stream-service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;map-service</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;ocean-stream-service (kafka window 和流处理)</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;ui-service （通过EventBus调用其他service实现业务逻辑,并提供接口给UI访问，或通过websocket连接UI）</p><p><br></p><p>二.Kafka Event Bus&nbsp;</p><p><span style="color: rgb(255, 70, 53);">ocean-ui 通过 http 或者 websocket 访问 ui-service&nbsp;</span></p><p><span style="color: rgb(255, 70, 53);">ui-service&nbsp;将 请求和参数发送到微服务对应的 KafkaTopic</span></p><p><span style="color: rgb(255, 70, 53);">微服务订阅指定的 Kafka Topic（eventbus.XxxService,每个Service都有一个对应的Topic ，例如alert-service 对应 eventbus.AlertService Topic）, 收到请求和参数 的Message后，通过jdbc 访问数据库拿数据，并将结果 发送到 Kafka 的 eventBus,resut Topic</span></p><p><span style="color: rgb(255, 70, 53);">ui-service&nbsp;订阅eventbus.result Topic,并将Resut Message 解析后发送给 ocean-ui</span></p><p><img src="//:0"></p><p><br></p><p>三.Ocean Stream service&nbsp;</p><p><br></p><p><span style="color: rgb(255, 70, 53);">主要数据来源于 agentAlert ,&nbsp;devices,telemetry 三个Kafka Topic，然后基于这些数据进行流处理，并将处理后的结果放到Redis或者指定的Kafka Topic。</span></p><p><span style="color: rgb(255, 70, 53);">分为以下类别和方法：</span></p><p>SelectKey</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keySelectorStream.startFilterDevice()&nbsp;（过滤devices Topic 的 message, 将action = create | update 的 message 转移到 devicesKTable Topic,避免不包含Location的 message 覆盖Ktable中的数据）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keySelectorStream.startSelectKeyForTelemetry() （Telemetry Stream Join devicesKtable ,将location 信息放到Message中，并以hallId作为Message的Key,将Message 转移到 hallTelemetry Topic）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;keySelectorStream.startSelectKeyForAlarm()&nbsp;（agentAlart Stream Join devicesKtable ,将location 信息放到Message中，并以hallId作为Message的Key,将Message 转移到 hallAlarm Topic）</p><p>SinkHallTelemetryToRedis</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kafkaStream.startHallTelemetryStream() (基于hallTelemetryTopic创建Stream,每15分钟一个窗口，分别计算窗口内每个Hall下面的telemetry,humidity,dewPoint的平均值和最新值，窗口结束时将该窗口的结果lpush 到Redis Topic #hallId_hallTelemetry并publish 到 Redis channel #hallTelemetry)</p><p>ITLoad</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;getCustomizedValueFromDB() （从Mysql中查询hall和building的customizedValue并放到内存中，这些值在计算ITLoad时需要用到）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kafkaStream.initPDUPointValueTableFromRedis()（从Redis中获取之前计算数据并放到内存中，避免了重启Ocean Stream Service 后，之前的数据丢失导致计算结果不正确）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;getCustomizedValueFromDBRegularly() （每五分钟查一次DB,更新customizedValue）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;kafkaStream.startHallITLoadStream()&nbsp;(基于hallTelemetry Topic计算每个Hall下面的kw point的 ITLoad：lastest value的总和，以及ITLoad%：lastest value的总和&nbsp;/ hall customizedValue,并以buildingId作为Key,将结果转移到buildingTelemetry Topic,同时将结果lpush到Redis Topic ##hallId_ITLoad并publish 到RedisChannle #ITLoad)</p><p>&nbsp;&nbsp;&nbsp;&nbsp;kafkaStream.startBuildingITLoadStream()&nbsp;(基于buildingTelemetry Topic计算每个Building 下面的 ITLoad ：Hall的ITLoad总和，以及ITLoad%：Hall的ITLoad总和/building customizedValue,并以buildingId作为Key,将结果转移到 siteTelemetry Topic,同时将结果lpush到Redis Topic ##buildingId_ITLoad并publish 到RedisChannle #ITLoad)</p><p>&nbsp;&nbsp;&nbsp;&nbsp;kafkaStream.startSiteITLoadStream()&nbsp;(基于siteTelemetry Topic计算每个Site下面的 ITLoad ：building的ITLoad总和,同时将结果lpush到Redis Topic ##siteId_ITLoad并publish 到RedisChannle #ITLoad)</p><p>SinkTelemetryToRedis</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startSubscribeTelemetryChannel(vertx) (获取当前所有被订阅的DeviceId并放到内存中，并订阅 Redis channel #telemetry_on_subscription_channel,该channel会接收新的被订阅的deviceId并放到内存中)</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startTelemetryStream() （将被订阅的Device下的Telemetry publish 到Redis channel #telemetry_sub_#deviceId）</p><p>TelemetryPeriod_1Min</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startPeriodStream(60L,telemetry, true)) (基于telemetry Topic创建stream,每分钟一个窗口，获取每个窗口内最后的一个value,在窗口结束时将窗口结果转移到 telemetry_60s Topic)</p><p>TelemetryPeriod_5Mins</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startPeriodStream(300L,telemetry_60s, false))&nbsp;(基于telemetry_60s Topic创建stream,每五分钟一个窗口，获取每个窗口内最后的一个value,在窗口结束时将窗口结果转移到 telemetry_300s Topic)</p><p>TelemetryPeriod_15Mins</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startPeriodStream(900L,telemetry_300s,false))&nbsp;(基于telemetry_300s Topic创建stream,每十五分钟一个窗口，获取每个窗口内最后的一个value,在窗口结束时将窗口结果转移到 telemetry_900s Topic)</p><p>TelemetryPeriod_1Hour</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startPeriodStream(3600L,telemetry_900s,false))&nbsp;(基于telemetry_900s Topic创建stream,每一小时一个窗口，获取每个窗口内最后的一个value,在窗口结束时将窗口结果转移到 telemetry_3600s Topic)</p><p>TelemetryPeriod_1day</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;telemetryStream.startPeriodStream(86400L,telemetry_3600s,false))&nbsp;(基于telemetry_3600s Topic创建stream,每一天一个窗口，获取每个窗口内最后的一个value,在窗口结束时将窗口结果转移到 telemetry_86400s Topic)</p><p>AlarmCount</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alarmStream.initSeverityMapFromRedis（）（从Redis中获取之前计算数据并放到内存中，避免了重启Ocean Stream Service 后，之前的数据丢失导致计算结果不正确）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alarmStream.startHallAlarmCountStream() （基于hallAlarm Topic创建Stream,计算每个Hall下面不同Severity 的Alarm的count 并将计算结果以FloorId作为Key转移到floorAlarm Topic,同时将结果Set到Redis Topic ##hallId_alarmCount,publish 到Redis channel #alarmCount)</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alarmStream.startFloorAlarmCountStream()&nbsp;（基于floorAlarmTopic创建Stream,计算每个Floor下面不同Severity 的Alarm的count 并将计算结果以FloorId作为Key转移到buildingAlarmTopicTopic,同时将结果Set到Redis Topic ##floorId_alarmCount,publish 到Redis channel #alarmCount）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alarmStream.startBuildingAlarmCountStream()&nbsp;（基于buildingAlarm Topic创建Stream,计算每个Building下面不同Severity 的Alarm的count 并将计算结果以FloorId作为Key转移到siteAlarm,同时将结果Set到Redis Topic ##buildingId_alarmCount,publish 到Redis channel #alarmCount）</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;alarmStream.startSiteAlarmCountStream()&nbsp;（基于siteAlarm Topic创建Stream,计算每个Site下面不同Severity 的Alarm的count,同时将结果Set到Redis Topic ##siteId_alarmCount,publish 到Redis channel #alarmCount）</p><p><br></p><p>数据流图如下：</p><p><img src="//:0"></p><p><br></p><p><br></p><p><br></p>