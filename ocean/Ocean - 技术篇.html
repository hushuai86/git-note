<attachment contenteditable="false" data-atts="%5B%5D" data-aid=".atts-9429d18b-7912-4e44-a272-aa51cbf2c601"></attachment><h1>Ocean - 技术篇Ocean - 技术篇</h1><p> </p><p><strong>一.Kafka&nbsp;</strong></p><p><br></p><p>1.概述&nbsp;</p><p>&nbsp;&nbsp;&nbsp;Kafka&nbsp;&nbsp;<span style="color: rgb(0, 0, 0);">是一个分布式、分区的、多副本的、多订阅者，基于zookeeper协调的分布式日志系统（也可以当做MQ系统）</span></p><p><br></p><p>2.相关术语</p><p><br></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;2.1　broker</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;Kafka 集群包含一个或多个服务器，服务器节点称为broker。</span></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;broker存储topic的数据。如果某topic有N个partition，集群有N个broker，那么每个broker存储该topic的一个partition。</span></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;如果某topic有N个partition，集群有(N+M)个broker，那么其中有N个broker存储该topic的一个partition，剩下的M个broker不存储该topic的partition数据。</span></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;如果某topic有N个partition，集群中broker数目少于N个，那么一个broker存储该topic的一个或多个partition。在实际生产环境中，尽量避免这种情况的发生，这种情况容易导致Kafka集群数据不均衡。</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;2.2&nbsp;Topic</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;2.3　Partition</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。partition中的数据是有序的，不同partition间的数据丢失了数据的顺序。如果topic有多个partition，消费数据时就不能保证数据的顺序。在需要严格保证消息的消费顺序的场景下，需要将partition数目设为1。</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;2.4　Producer</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息</span><strong style="color: rgb(255, 0, 0); background-color: rgb(255, 255, 255);">追加</strong><span style="color: rgb(0, 0, 0);">到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;2.5　Consumer</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;消费者可以从broker中读取数据。消费者可以消费多个topic中的数据。</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;2.6　Consumer Group</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</span></p><p><span style="color: rgb(255, 70, 53);">&nbsp;&nbsp;&nbsp;同一个Consumer Group 的 consumer</span> <span style="color: rgb(255, 70, 53);">消费同一个Topic 时，Message会分发到 每个&nbsp;Consumer,这表示同一个Consumer Group 的consumer 不会同时消费同一个Topic的 同一条Messsage</span></p><p><span style="color: rgb(255, 70, 53);">如果是不同Consumer Group 的consumer 消费同一个topic时，每个Topic 都会消费到这个Topic接收的所有Message</span></p><p><span style="color: rgb(0, 0, 0);">3.Ocean 中的Kafka应用</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;3.1 数据传递&nbsp;</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;Ocean 中的数据通过kafka mqtt&nbsp;connector&nbsp;从</span> <span style="color: rgb(0, 0, 0);">Kooppi 的</span>EMQX<span style="color: rgb(0, 0, 0);">服务器同步到Kafka的topic,然后我们消费 kafka 的topic 并进行处理。</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;3.1&nbsp;EventBus&nbsp;</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;Ocean中使用 Kafka 作为消息总线，进行微服务间的通讯，ui-service 将请求发送到不同微服务对应的 Topic, 微服务订阅相应的Topic,在接收到请求后，执行业务逻辑代码，并将响应内容发送到 result Topic ,ui-service 通过订阅 result Topic ，接收并解析响应内容。&nbsp;</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;3.2&nbsp;&nbsp;Kafka Connector</strong></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;Ocean中由于版权原因，我们自己开发了简单的 Cassandra 和&nbsp;&nbsp;Mysql 的 Connector，用于从Topic 同步数据到Cassandra 和&nbsp;&nbsp;Mysql，</span><span style="color: unset;">同时我们使用了开源Redis connector 用于同步Telemetry 到 Redis.</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;3.3&nbsp;&nbsp;Kafka Stream&nbsp;</strong></p><p>&nbsp;&nbsp;Kafka Stream&nbsp; <span style="color: rgb(51, 51, 51);">提供了对存储于Kafka内的数据进行流式处理和分析的功能,</span> <span style="color: rgb(51, 51, 51);">在流式计算模型中，输入是持续的，可以认为在时间上是无界的，也就意味着，永远拿不到全量数据去做计算。同时，计算结果是持续输出的，也即计算结果在时间上也是无界的。流式计算一般对实时性要求较高，同时一般是先定义目标计算，然后数据到来之后将计算逻辑应用于数据.</span></p><p><span style="color: rgb(51, 51, 51);">&nbsp;&nbsp;&nbsp;</span><span style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">KTable,KStream和</span> globalKTable<span style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">是Kafka Stream中非常重要的三个概念，它们是Kafka实现各种语义的基础。因此这里有必要分析下三者的区别。</span></p><p><span style="color: rgb(51, 51, 51);">KStream是一个数据流，可以认为所有记录都通过Insert only的方式插入进这个数据流里。</span></p><p><span style="color: rgb(51, 51, 51);">&nbsp;&nbsp;&nbsp;KTable代表一个完整的数据集，可以理解为数据库中的表。由于每条记录都是Key-Value对，这里可以将Key理解为数据库中的Primary Key，而Value可以理解为一行记录。可以认为KTable中的数据都是通过Update only的方式进入的。也就意味着，如果KTable对应的Topic中新进入的数据的Key已经存在，那么从KTable只会取出同一Key对应的最后一条数据，相当于新的数据更新了旧的数据.</span></p><p><span style="color: rgb(51, 51, 51);">&nbsp;&nbsp;&nbsp;Kafka根据数据的key来分区，一般情况下相同的key会存入相同的分区中，如果使用两个KTable来进行join操作，因为两个表的数据在不同的分区中，甚至在不同的机器中，那么在进行join操作的时候需要进行数据分发。而硬盘的不断寻址读写操作和网络延迟会严重影响性能,</span></p><p><span style="color: rgb(51, 51, 51);">&nbsp;&nbsp;&nbsp;Global table 是一个高层的抽象,KTable在所有运行的Kafka Streams实例之间共享数据，而GlobalKTable</span><span style="color: rgb(51, 51, 51); background-color: transparent;">有一份所有数据的完整副本实例,</span></p><p><strong style="color: rgb(255, 255, 255); background-color: rgb(43, 102, 149);">&nbsp;&nbsp;&nbsp;3.4&nbsp;&nbsp;Kafka Time Window&nbsp;</strong></p><p><span style="color: rgb(77, 77, 77);">&nbsp;&nbsp;TimeWindow 是基于Kafka Stream 的在实时计算中非常重要的功能。它根据时间窗口做聚合，Ocean 中，我们用Kafka Stream&nbsp;实现了 ITLoad,Alarm Count 的计算,用Time Window 计算 HallTelemetry 的平均值，以及 获取不同时间间隔内（1分钟，5分钟，15分钟，1小时，1天）最新的Telemetry Value.</span></p><p><br></p><p><strong style="color: rgb(51, 51, 51);">二.Redis</strong></p><p><span style="color: rgb(51, 51, 51);">1.概述&nbsp;</span></p><p>	<span style="color: rgb(51, 51, 51);">redis是一个key-value存储系统，支持多种类型，&nbsp;</span>	<span style="color: rgb(51, 51, 51); background-color: rgb(255, 255, 255);">string(字符串)、list(</span>	<a href="https://baike.baidu.com/item/%E9%93%BE%E8%A1%A8" target="_blank" style="color: rgb(19, 110, 194); background-color: rgb(255, 255, 255);">链表</a>	<span style="color: rgb(51, 51, 51);">)、set(集合)、zset(sorted set --有序集合)和hash（哈希类型）</span></p><p><span style="color: rgb(51, 51, 51);">Redis具备的特点是：</span></p><ul><li><span style="color: rgb(51, 51, 51);">基于内存运行，性能高效</span></li><li><span style="color: rgb(51, 51, 51);">支持分布式，理论上可以无限扩展</span></li><li><span style="color: rgb(51, 51, 51);">key-value存储系统</span></li><li><span style="color: rgb(51, 51, 51);">单进程单线程模型</span></li><li><span style="color: rgb(51, 51, 51);">丰富的数据类型</span></li><li><span style="color: rgb(51, 51, 51);">操作具有原子性</span></li><li><span style="color: rgb(51, 51, 51);">持久化</span></li><li><span style="color: rgb(51, 51, 51);">高并发读写</span></li><li><span style="color: rgb(51, 51, 51);">开源的使用ANSI C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API</span></li></ul><p><br></p><p><span style="color: rgb(51, 51, 51);">2.</span><span style="color: rgb(0, 0, 0);">Ocean 中的</span>	<span style="color: rgb(51, 51, 51);">redis</span><span style="color: rgb(0, 0, 0);">应用</span></p><p><br></p><ul><li><span style="color: rgb(0, 0, 0); background-color: rgb(238, 238, 238);">事件发布或订阅</span><span style="color: rgb(0, 0, 0);">: Ocean 中&nbsp;ITLoad,Telemetry,AlarmCount 都通过 Stream Service publish 到Redis Channel ，然后Ui-service 进行Subscribe 并通过websocket 更新UI</span></li><li><span style="color: rgb(0, 0, 0);">缓存： 在UI-service 中，参照Spring 的源代码自定义了缓存注解，并提供了基于Redis的实现。</span></li><li><span style="color: rgb(0, 0, 0);">数据存取： ocean-stream-service 中将&nbsp;ITLoad,AlarmCount,HallTelemetry等数据通过 Set,lpush等Redis 操作存到Redis,并在ui-service 中通过get,lrange等操作进行取用</span></li><li>Incr 和&nbsp;expire&nbsp;： 通过 Redis Incr&nbsp;和 expire 命令 生成 每天不重复的AlarmId</li></ul><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;</span></p><p><span style="color: rgb(0, 0, 0);">&nbsp;&nbsp;&nbsp;</span></p><p><strong>三.Vertx</strong></p><p><span style="color: rgb(77, 77, 77);">&nbsp;&nbsp;</span> <span style="color: rgb(77, 77, 77);">&nbsp;&nbsp;&nbsp;</span> <span style="color: rgb(77, 77, 77);">&nbsp;Vert.x最大的特点就在于异步（底层基于Netty），通过事件循环（EventLoop）来调起存储在异步任务队列（CallBackQueue）中的任务，大大降低了传统阻塞模型中线程对于操作系统的开销。因此相比较传统的阻塞模型，异步模型能够很大层度的提高系统的并发量。</span></p><p><span style="color: rgb(77, 77, 77);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vert.x除了异步之外，还提供了非常多的吸引人的技术，比如EventBus，通过EventBus可以非常简单的实现分布式消息，进而为分布式系统调用，微服务奠定基础。除此之外，还提供了对多种客户端的支持，比如Redis，RabbitMQ，Kafka等等。</span></p><p><span style="color: rgb(77, 77, 77);">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Vert.x是事件驱动的，其处理请求的高性能也是基于其事件机制。Vert.x的事件机制中有几个非常重要的概念：Event Loop、Event Loop Vertical、Worker Vertical、Event Bus、Vert.x Module。</span></p><p><span style="color: rgb(77, 77, 77);">Event Loop：即事件循环，是由Vert.x启动的事件处理线程，也是Vert.x项目对外开放的入口，Vert.x由此接收请求事件。一个Vert.x有一个或多个事件循环线程组成，线程最大数量为主机有效的CPU核数。</span></p><p><span style="color: rgb(77, 77, 77);">Event Loop Vertical：事件的业务处理线程，存在于Event Loop中，用于处理非阻塞短任务。</span></p><p><span style="color: rgb(77, 77, 77);">Worker Vertical : 事件的业务处理线程，用于处理长任务阻塞任务。</span></p><p><span style="color: rgb(77, 77, 77);">Event Bus：即事件总线，是Vert.x事件模型中最核心的部分，所有的事件都经由事件总线进行分发，包括Vertical之间的通信事件。</span></p><p><span style="color: rgb(77, 77, 77);">Vert.x Module : Vert.x项目模块，一个应用通常由多个模块组成，每个模块一般包含多个Vertical。</span></p><p><br></p><p><strong style="color: rgb(64, 64, 64);">四. Dagger2 依赖注入</strong></p><p><span style="color: rgb(77, 77, 77);">Dagger 是一个可以用于Java及Android平台的依赖注入框架，其注入过程完全是静态的在编译时期完成的（通过编译时产生代码的方式，区别于Spring等框架的依赖反射的方式，反射是基于运行时的）</span></p><p><span style="color: rgb(77, 77, 77);">Ocean 中 使用 Dagger 实现依赖注入，具体请看代码。</span></p><p><br></p><p><strong>五. Cassandra</strong></p><p>	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Cassandra是一套开源分布式NoSQL数据库系统,Cassarndra 可以处理大量数据集，所以在Ocean 用来保存数量巨大的 Telemetry数据。</p><p>&nbsp;&nbsp;&nbsp;&nbsp;Cassandra&nbsp;&nbsp;的查询语句 （CQL） 有很多限制。基于在Ocean中的尝试，在select ，update， delete 等操作中，如果要加入一些条件限制，则必须要在cql中指定全部主键。</p><p><br></p><p><img src="//:0"></p><p><br></p><p>六.Docker &amp; K8s</p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p><p><br></p>